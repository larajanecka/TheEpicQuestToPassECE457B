Feature extraction was a very large portion of this project, done with perhaps the least prior knowledge. Its main goal is to most accurately represent reality and the way humans hear music and detect beats within said music. By improving on the features fed into the neural network used the accuracy of this system could greatly improve.

The features extracted for the use of this project were the most simple possible. Their accuracy could have been improved using more refined techniques. The bandwidth power variance was found by summing the energy across all values that fall in a frequency range. This is a very naive approach and the paper referenced for finding the bandwidth break values using much more advanced signal processing techniques to implement a filter bank with these values. This was pointed to as a potential source of inaccuracy, improving on these would greatly increase the relevancy of the features extracted from the input used.

Most songs have different sections where the tone is completely. This fact was not leveraged by this system at all. In a more complex system this could be leveraged this by estimating breaks between chorus, verse, and bridge to only compare values within those sections. This would allow more accurate data to be extracted by comparing local values to a much larger neighborhood.

Music is most usually described using genres. This data is downloaded with the song as part of the data pipeline. The genre a song is classified can be used to give an estimated value for its beats per minute which can be used to roughly estimate the gap between beats. This value would greatly help with the problem of many beats occurring in sequence. It would also allow the system to more accurately represent how humans hear a song by using the tags assigned to the song as reference.
