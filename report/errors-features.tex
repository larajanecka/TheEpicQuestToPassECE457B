Many of the methods for extracting features from the wave file were very naive introduced approximations and rooms for error. These could have influenced more inaccuracies than a purely signal processing approach would have. It was assumed that the introduction of a neural network would compensate for weaker feature extraction.\\

The size of the neighborhood was selected using the general value of one second. This was chosen due to its unit nature and through basic reason. It should have been a tunable parameter and configured through experimentation. The neighborhood size could have greatly effected the accuracy of the data fed into the network as it was one of the primary sources of memory within the system. It is likely that one full second was far too large as it included three hundred chunks and quite a lot can happen in one second of as song, particularly one second of a dance styled song where the beats per minute are often near 140.\\

The frequencies used to break apart the bandwidths of a chunk were taken from as paper from 1998. These values were calibrated for the author's purely signal processing approach to the problem and might not have been the best for this system's approach. Other systems that more closely resemble this one have used other frequency break points determined by musical values and tones. Following one of these methods of analyzing bandwidth values would have more closely approximated the way humans hear music.\\

The sensitivity of human hearing differs greatly at different frequencies which was not considered when evaluating the way frequency interacts with how humans hear songs. The amplitude for a given frequency was its assumed ``hearablity'' value without taking into consideration the frequency itself and how that would effect how well humans would hear it. This could have been a major source of inaccuracy in the features fed into the neural network.\\
